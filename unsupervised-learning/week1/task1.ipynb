{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming Assignment: Размещение баннеров\n",
    "\n",
    "Представим, что международное круизное агентство Carnival Cruise Line решило себя разрекламировать с помощью баннеров и обратилось для этого к вам. Чтобы протестировать, велика ли от таких баннеров польза, их будет размещено всего 20 штук по всему миру. Вам надо выбрать 20 таких локаций для размещения, чтобы польза была большой и агентство продолжило с вами сотрудничать.\n",
    "\n",
    "Агентство крупное, и у него есть несколько офисов по всему миру. Вблизи этих офисов оно и хочет разместить баннеры — легче договариваться и проверять результат. Также эти места должны быть популярны среди туристов.\n",
    "\n",
    "Для поиска оптимальных мест воспользуемся базой данных крупнейшей социальной сети, основанной на локациях — Foursquare.\n",
    "\n",
    "Часть открытых данных есть, например, на сайте archive.org:\n",
    "\n",
    "https://archive.org/details/201309_foursquare_dataset_umn\n",
    "\n",
    "Скачаем любым удобным образом архив fsq.zip с этой страницы.\n",
    "\n",
    "Нас будет интересовать файл checkins.dat. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('checkins.dat') as dat_file, open('checkins.csv', 'w') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "\n",
    "    for line in dat_file:\n",
    "        row = [field.strip() for field in line.split('|')]\n",
    "        if len(row) == 6 and row[3] and row[4]:\n",
    "            csv_writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью pandas построим DataFrame и убедимся, что все 396634 строки с координатами считаны успешно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(396634, 6)\n",
      "Index(['id', 'user_id', 'venue_id', 'latitude', 'longitude', 'created_at'], dtype='object')\n",
      "(100000, 6)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "\n",
    "data = pd.read_csv('checkins.csv')\n",
    "data_100k = data.loc[:99999]\n",
    "print(data.shape)\n",
    "print(data.columns)\n",
    "print(data_100k.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь необходимо кластеризовать данные координаты, чтобы выявить центры скоплений туристов. Поскольку баннеры имеют сравнительно небольшую площадь действия, нам нужен алгоритм, позволяющий ограничить размер кластера и не зависящий от количества кластеров.\n",
    "\n",
    "Используйте MeanShift, указав bandwidth=0.1, что в переводе из градусов в метры колеблется примерно от 5 до 10 км в средних широтах.\n",
    "\n",
    "Примечание: на 396634 строках кластеризация будет работать долго. Быть очень терпеливым не возбраняется — результат от этого только улучшится. Но для того, чтобы сдать задание, понадобится сабсет из первых 100 тысяч строк. Это компромисс между качеством и затраченным временем. Обучение алгоритма на всём датасете занимает около часа, а на 100 тыс. строк — примерно 2 минуты, однако этого достаточно для получения корректных результатов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MeanShift(bandwidth=0.1, bin_seeding=False, cluster_all=True, min_bin_freq=1,\n",
      "          n_jobs=None, seeds=None)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import MeanShift\n",
    "\n",
    "coors_100k_df = data_100k[['latitude', 'longitude']]\n",
    "coors_100k_list = coors_100k_df.values.tolist()\n",
    "\n",
    "clustering = MeanShift(bandwidth=0.1).fit(coors_100k_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bs/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>venue_id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>created_at</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>984222</td>\n",
       "      <td>15824</td>\n",
       "      <td>5222</td>\n",
       "      <td>38.895112</td>\n",
       "      <td>-77.036366</td>\n",
       "      <td>2012-04-21 17:43:47</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>984234</td>\n",
       "      <td>44652</td>\n",
       "      <td>5222</td>\n",
       "      <td>33.800745</td>\n",
       "      <td>-84.410520</td>\n",
       "      <td>2012-04-21 17:43:43</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>984291</td>\n",
       "      <td>105054</td>\n",
       "      <td>5222</td>\n",
       "      <td>45.523452</td>\n",
       "      <td>-122.676207</td>\n",
       "      <td>2012-04-21 17:39:22</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>984318</td>\n",
       "      <td>2146539</td>\n",
       "      <td>5222</td>\n",
       "      <td>40.764462</td>\n",
       "      <td>-111.904565</td>\n",
       "      <td>2012-04-21 17:35:46</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>984232</td>\n",
       "      <td>93870</td>\n",
       "      <td>380645</td>\n",
       "      <td>33.448377</td>\n",
       "      <td>-112.074037</td>\n",
       "      <td>2012-04-21 17:38:18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  user_id  venue_id   latitude   longitude           created_at  \\\n",
       "0  984222    15824      5222  38.895112  -77.036366  2012-04-21 17:43:47   \n",
       "1  984234    44652      5222  33.800745  -84.410520  2012-04-21 17:43:43   \n",
       "2  984291   105054      5222  45.523452 -122.676207  2012-04-21 17:39:22   \n",
       "3  984318  2146539      5222  40.764462 -111.904565  2012-04-21 17:35:46   \n",
       "4  984232    93870    380645  33.448377 -112.074037  2012-04-21 17:38:18   \n",
       "\n",
       "   cluster  \n",
       "0        5  \n",
       "1        7  \n",
       "2       30  \n",
       "3       65  \n",
       "4        1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_100k['cluster'] = clustering.labels_\n",
    "data_100k.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Некоторые из получившихся кластеров содержат слишком мало точек — такие кластеры не интересны рекламодателям. Поэтому надо определить, какие из кластеров содержат, скажем, больше 15 элементов. Центры этих кластеров и являются оптимальными для размещения.\n",
    "\n",
    "Осталось определить 20 ближайших к ним центров кластеров. Т.е. посчитать дистанцию до ближайшего офиса для каждой точки и выбрать 20 с наименьшим значением.\n",
    "\n",
    "Примечание: при подсчете расстояний и в кластеризации можно пренебречь тем, что Земля круглая, так как в точках, расположенных близко друг к другу погрешность мала, а в остальных точках значение достаточно велико."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bs/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "from haversine import haversine, Unit\n",
    "\n",
    "offices_coors = [(33.751277, -118.188740), (25.867736, -80.324116), (51.503016, -0.075479),(52.378894, 4.885084),(39.366487, 117.036146),(-33.868457, 151.205134)]\n",
    "\n",
    "data_grouped_filtered_clusters = data_100k.groupby('cluster').size()\n",
    "\n",
    "clusters = pd.DataFrame({'cluster':data_grouped_filtered_clusters.index, 'size':data_grouped_filtered_clusters.values})\n",
    "clusters['center'] = clusters.apply(lambda row: clustering.cluster_centers_[row['cluster']], axis = 1) \n",
    "\n",
    "filtered_clusters = clusters[clusters['size'] > 15]\n",
    "filtered_clusters['min_dst_to office'] = clusters.apply(lambda row: min([haversine(row['center'], office) for office in offices_coors]), axis = 1) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для сдачи задания выберите из получившихся 20 центров тот, который наименее удален от ближайшего к нему офиса. Ответ в этом задании — широта и долгота этого центра, записанные через пробел."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[52.37296399  4.89231722]\n"
     ]
    }
   ],
   "source": [
    "sorted_filtered_clusters = filtered_clusters.sort_values(by=['min_dst_to office'])\n",
    "nearest_cluster_center = sorted_filtered_clusters.iloc[0]['center']\n",
    "\n",
    "print(nearest_cluster_center)\n",
    "\n",
    "with open(\"ans.txt\", \"w\") as fout:\n",
    "    fout.write(' '.join([str(x) for x in nearest_cluster_center]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
